{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import torch\n",
    "import random as rd\n",
    "import numpy\n",
    "\n",
    "rd.seed(0)\n",
    "numpy.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
      "       'pixel6', 'pixel7', 'pixel8',\n",
      "       ...\n",
      "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
      "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
      "      dtype='object', length=785)\n"
     ]
    }
   ],
   "source": [
    "train=pandas.read_csv(r\"C:\\Users\\egor-\\OneDrive\\Рабочий стол\\Егор\\Mnist_kaggle\\train.csv\")\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=numpy.array(train.drop(columns=[\"label\"]))/255.0\n",
    "target=numpy.array(train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), (28, 28))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(features,target,test_size=0.4,shuffle=True)\n",
    "\n",
    "x_train=x_train.reshape([x_train.shape[0],28,28])\n",
    "x_test=x_test.reshape([x_test.shape[0],28,28])\n",
    "x_test[0].shape,x_train[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([25200, 1, 28, 28]), torch.Size([16800, 1, 28, 28]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=torch.FloatTensor(x_train)\n",
    "x_test=torch.FloatTensor(x_test)\n",
    "y_train=torch.LongTensor(y_train)\n",
    "y_test=torch.LongTensor(y_test)\n",
    "\n",
    "x_train=x_train.unsqueeze(1).float()\n",
    "x_test=x_test.unsqueeze(1).float()\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Le_Net(torch.nn.Module):\n",
    "    def __init__(self,conv_size=5,activation=\"tanh\",pooling=\"avg\",use_batch_normalize=False):\n",
    "        super(Le_Net,self).__init__()\n",
    "        self.conv_size=conv_size\n",
    "        self.use_batch_normalize=use_batch_normalize\n",
    "        \n",
    "        if activation==\"tanh\":\n",
    "            activation_func=torch.nn.Tanh()\n",
    "        elif activation==\"relu\":\n",
    "            activation_func=torch.nn.ReLU()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if pooling==\"avg\":\n",
    "            pooling_layer=torch.nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "        elif pooling==\"max\":\n",
    "            pooling_layer=torch.nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        \n",
    "        # first convolutional layer\n",
    "        if self.conv_size==5:\n",
    "            self.conv1=torch.nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5,padding=2)\n",
    "        elif self.conv_size==3:\n",
    "            self.conv1_1=torch.nn.Conv2d(in_channels=1,out_channels=6,kernel_size=3,padding=1)\n",
    "            self.conv1_2=torch.nn.Conv2d(in_channels=6,out_channels=6,kernel_size=3,padding=1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.act1=activation_func\n",
    "        self.bn1=torch.nn.BatchNorm2d(num_features=6)\n",
    "        self.pool1=pooling_layer\n",
    "\n",
    "        #second convolutional layer\n",
    "        if self.conv_size==5:\n",
    "            self.conv2=torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,padding=0)\n",
    "        elif self.conv_size==3:\n",
    "            self.conv2_1=torch.nn.Conv2d(in_channels=6,out_channels=16,kernel_size=3,padding=0)\n",
    "            self.conv2_2=torch.nn.Conv2d(in_channels=16,out_channels=16,kernel_size=3,padding=0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.act2=activation_func\n",
    "        self.bn2=torch.nn.BatchNorm2d(num_features=16)\n",
    "        self.pool2=pooling_layer\n",
    "        \n",
    "        #fullconnected layers\n",
    "        self.fc1=torch.nn.Linear(5*5*16,120)\n",
    "        self.act3=activation_func\n",
    "        self.fc2=torch.nn.Linear(120,84)\n",
    "        self.act4=activation_func\n",
    "        self.fc3=torch.nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        if self.conv_size==5:\n",
    "            x=self.conv1(x)\n",
    "        elif self.conv_size==3:\n",
    "            x=self.conv1_1(x)\n",
    "            x=self.conv1_2(x)\n",
    "        x=self.act1(x)\n",
    "        x=self.bn1(x)\n",
    "        x=self.pool1(x)\n",
    "        \n",
    "        if self.conv_size==5:\n",
    "            x=self.conv2(x)\n",
    "        elif self.conv_size==3:\n",
    "            x=self.conv2_1(x)\n",
    "            x=self.conv2_2(x)\n",
    "        x=self.act2(x)\n",
    "        x=self.bn2(x)\n",
    "        x=self.pool2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "        \n",
    "        x=self.fc1(x)\n",
    "        x=self.act3(x)\n",
    "        x=self.fc2(x)\n",
    "        x=self.act4(x)\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "neural_net=Le_Net(conv_size=3,activation=\"relu\",pooling=\"max\",use_batch_normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=torch.nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(neural_net.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0976)\n",
      "tensor(0.1020)\n",
      "tensor(0.1065)\n",
      "tensor(0.1110)\n",
      "tensor(0.1176)\n",
      "tensor(0.1247)\n",
      "tensor(0.1343)\n",
      "tensor(0.1439)\n",
      "tensor(0.1555)\n",
      "tensor(0.1679)\n",
      "tensor(0.1805)\n",
      "tensor(0.1946)\n",
      "tensor(0.2098)\n",
      "tensor(0.2242)\n",
      "tensor(0.2404)\n",
      "tensor(0.2562)\n",
      "tensor(0.2731)\n",
      "tensor(0.2885)\n",
      "tensor(0.3015)\n",
      "tensor(0.3162)\n",
      "tensor(0.3296)\n",
      "tensor(0.3452)\n",
      "tensor(0.3583)\n",
      "tensor(0.3721)\n",
      "tensor(0.3896)\n",
      "tensor(0.4069)\n",
      "tensor(0.4241)\n",
      "tensor(0.4439)\n",
      "tensor(0.4639)\n",
      "tensor(0.4841)\n",
      "tensor(0.5016)\n",
      "tensor(0.5136)\n",
      "tensor(0.5233)\n",
      "tensor(0.5352)\n",
      "tensor(0.5442)\n",
      "tensor(0.5525)\n",
      "tensor(0.5583)\n",
      "tensor(0.5674)\n",
      "tensor(0.5749)\n",
      "tensor(0.5816)\n",
      "tensor(0.5886)\n",
      "tensor(0.5917)\n",
      "tensor(0.5973)\n",
      "tensor(0.6024)\n",
      "tensor(0.6077)\n",
      "tensor(0.6124)\n",
      "tensor(0.6157)\n",
      "tensor(0.6177)\n",
      "tensor(0.6219)\n",
      "tensor(0.6261)\n",
      "tensor(0.6312)\n",
      "tensor(0.6365)\n",
      "tensor(0.6413)\n",
      "tensor(0.6438)\n",
      "tensor(0.6479)\n",
      "tensor(0.6511)\n",
      "tensor(0.6554)\n",
      "tensor(0.6594)\n",
      "tensor(0.6646)\n",
      "tensor(0.6682)\n",
      "tensor(0.6721)\n",
      "tensor(0.6769)\n",
      "tensor(0.6812)\n",
      "tensor(0.6867)\n",
      "tensor(0.6910)\n",
      "tensor(0.6929)\n",
      "tensor(0.6953)\n",
      "tensor(0.6970)\n",
      "tensor(0.6985)\n",
      "tensor(0.6990)\n",
      "tensor(0.7017)\n",
      "tensor(0.7037)\n",
      "tensor(0.7060)\n",
      "tensor(0.7093)\n",
      "tensor(0.7118)\n",
      "tensor(0.7117)\n",
      "tensor(0.7116)\n",
      "tensor(0.7120)\n",
      "tensor(0.7120)\n",
      "tensor(0.7105)\n",
      "tensor(0.7095)\n",
      "tensor(0.7093)\n",
      "tensor(0.7095)\n",
      "tensor(0.7102)\n",
      "tensor(0.7105)\n",
      "tensor(0.7113)\n",
      "tensor(0.7133)\n",
      "tensor(0.7149)\n",
      "tensor(0.7158)\n",
      "tensor(0.7189)\n",
      "tensor(0.7223)\n",
      "tensor(0.7251)\n",
      "tensor(0.7281)\n",
      "tensor(0.7307)\n",
      "tensor(0.7344)\n",
      "tensor(0.7388)\n",
      "tensor(0.7444)\n",
      "tensor(0.7492)\n",
      "tensor(0.7529)\n",
      "tensor(0.7554)\n",
      "tensor(0.7595)\n",
      "tensor(0.7647)\n",
      "tensor(0.7686)\n",
      "tensor(0.7704)\n",
      "tensor(0.7726)\n",
      "tensor(0.7761)\n",
      "tensor(0.7780)\n",
      "tensor(0.7801)\n",
      "tensor(0.7802)\n",
      "tensor(0.7817)\n",
      "tensor(0.7824)\n",
      "tensor(0.7827)\n",
      "tensor(0.7843)\n",
      "tensor(0.7861)\n",
      "tensor(0.7862)\n",
      "tensor(0.7871)\n",
      "tensor(0.7880)\n",
      "tensor(0.7893)\n",
      "tensor(0.7908)\n",
      "tensor(0.7930)\n",
      "tensor(0.7955)\n",
      "tensor(0.7962)\n",
      "tensor(0.7971)\n",
      "tensor(0.7995)\n",
      "tensor(0.8023)\n",
      "tensor(0.8049)\n",
      "tensor(0.8066)\n",
      "tensor(0.8102)\n",
      "tensor(0.8135)\n",
      "tensor(0.8160)\n",
      "tensor(0.8182)\n",
      "tensor(0.8207)\n",
      "tensor(0.8237)\n",
      "tensor(0.8258)\n",
      "tensor(0.8283)\n",
      "tensor(0.8290)\n",
      "tensor(0.8300)\n",
      "tensor(0.8306)\n",
      "tensor(0.8312)\n",
      "tensor(0.8311)\n",
      "tensor(0.8315)\n",
      "tensor(0.8323)\n",
      "tensor(0.8329)\n",
      "tensor(0.8338)\n",
      "tensor(0.8349)\n",
      "tensor(0.8373)\n",
      "tensor(0.8395)\n",
      "tensor(0.8410)\n",
      "tensor(0.8429)\n",
      "tensor(0.8436)\n",
      "tensor(0.8439)\n",
      "tensor(0.8444)\n",
      "tensor(0.8450)\n",
      "tensor(0.8448)\n",
      "tensor(0.8452)\n",
      "tensor(0.8466)\n",
      "tensor(0.8480)\n",
      "tensor(0.8485)\n",
      "tensor(0.8482)\n",
      "tensor(0.8492)\n",
      "tensor(0.8491)\n",
      "tensor(0.8505)\n",
      "tensor(0.8521)\n",
      "tensor(0.8527)\n",
      "tensor(0.8533)\n",
      "tensor(0.8540)\n",
      "tensor(0.8549)\n",
      "tensor(0.8557)\n",
      "tensor(0.8563)\n",
      "tensor(0.8587)\n",
      "tensor(0.8598)\n",
      "tensor(0.8619)\n",
      "tensor(0.8629)\n",
      "tensor(0.8648)\n",
      "tensor(0.8665)\n",
      "tensor(0.8679)\n",
      "tensor(0.8693)\n",
      "tensor(0.8705)\n",
      "tensor(0.8711)\n",
      "tensor(0.8720)\n",
      "tensor(0.8723)\n",
      "tensor(0.8728)\n",
      "tensor(0.8739)\n",
      "tensor(0.8745)\n",
      "tensor(0.8748)\n",
      "tensor(0.8751)\n",
      "tensor(0.8751)\n",
      "tensor(0.8764)\n",
      "tensor(0.8784)\n",
      "tensor(0.8794)\n",
      "tensor(0.8791)\n",
      "tensor(0.8801)\n",
      "tensor(0.8804)\n",
      "tensor(0.8810)\n",
      "tensor(0.8817)\n",
      "tensor(0.8820)\n",
      "tensor(0.8821)\n",
      "tensor(0.8836)\n",
      "tensor(0.8845)\n",
      "tensor(0.8858)\n",
      "tensor(0.8868)\n",
      "tensor(0.8879)\n",
      "tensor(0.8889)\n",
      "tensor(0.8900)\n",
      "tensor(0.8905)\n",
      "tensor(0.8913)\n",
      "tensor(0.8918)\n",
      "tensor(0.8927)\n",
      "tensor(0.8930)\n",
      "tensor(0.8933)\n",
      "tensor(0.8945)\n",
      "tensor(0.8950)\n",
      "tensor(0.8953)\n",
      "tensor(0.8963)\n",
      "tensor(0.8967)\n",
      "tensor(0.8977)\n",
      "tensor(0.8985)\n",
      "tensor(0.8990)\n",
      "tensor(0.8998)\n",
      "tensor(0.9003)\n",
      "tensor(0.9008)\n",
      "tensor(0.9013)\n",
      "tensor(0.9018)\n",
      "tensor(0.9027)\n",
      "tensor(0.9031)\n",
      "tensor(0.9039)\n",
      "tensor(0.9039)\n",
      "tensor(0.9041)\n",
      "tensor(0.9045)\n",
      "tensor(0.9042)\n",
      "tensor(0.9046)\n",
      "tensor(0.9047)\n",
      "tensor(0.9058)\n",
      "tensor(0.9058)\n",
      "tensor(0.9069)\n",
      "tensor(0.9079)\n",
      "tensor(0.9081)\n",
      "tensor(0.9080)\n",
      "tensor(0.9087)\n",
      "tensor(0.9090)\n",
      "tensor(0.9095)\n",
      "tensor(0.9101)\n",
      "tensor(0.9110)\n",
      "tensor(0.9107)\n",
      "tensor(0.9112)\n",
      "tensor(0.9116)\n",
      "tensor(0.9116)\n",
      "tensor(0.9119)\n",
      "tensor(0.9121)\n",
      "tensor(0.9115)\n",
      "tensor(0.9116)\n",
      "tensor(0.9121)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-89fc3176c6a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mloss_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mloss_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size=100\n",
    "for epoch in range(10000):\n",
    "    order=numpy.random.permutation(len(x_train))\n",
    "    for start_index in range(0,len(x_train),batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        batch_indexes=order[start_index:start_index+batch_size]\n",
    "        \n",
    "        x_batch=x_train[batch_indexes]\n",
    "        y_batch=y_train[batch_indexes]\n",
    "        \n",
    "        predict=neural_net.forward(x_batch)\n",
    "        \n",
    "        loss_val=loss(predict,y_batch)\n",
    "        loss_val.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        if epoch%100==0:\n",
    "            \n",
    "            test_predict=neural_net.forward(x_test).argmax(dim=1)\n",
    "            print((test_predict==y_test).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(r\"C:\\Users\\egor-\\OneDrive\\Рабочий стол\\Егор\\Mnist_kaggle\\neural_net.txt\",\"wb\") as file:\n",
    "    pickle.dump(neural_net,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pandas.read_csv(r\"C:\\Users\\egor-\\OneDrive\\Рабочий стол\\Егор\\Mnist_kaggle\\test.csv\")\n",
    "test_data=numpy.array(test)/255.0\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n",
      "       'pixel7', 'pixel8', 'pixel9',\n",
      "       ...\n",
      "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
      "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
      "      dtype='object', length=784)\n"
     ]
    }
   ],
   "source": [
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000, 1, 28, 28])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=test_data.reshape([test_data.shape[0],28,28])\n",
    "\n",
    "test_data=torch.FloatTensor(test_data).unsqueeze(1).float()\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts=neural_net.forward(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b1b14f89a64f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\egor-\\OneDrive\\Рабочий стол\\Егор\\Mnist_kaggle\\sample_submission.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mfieldnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ImageId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(r\"C:\\Users\\egor-\\OneDrive\\Рабочий стол\\Егор\\Mnist_kaggle\\sample_submission.csv\", 'w') as f:\n",
    "    fieldnames = ['ImageId', 'Label']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    i = 1\n",
    "    for elem in preds:\n",
    "        writer.writerow({'ImageId': i, 'Label': elem})\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
